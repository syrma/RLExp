{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import gym\n",
    "import pybullet_envs\n",
    "import time\n",
    "import math\n",
    "import argparse\n",
    "import tempfile\n",
    "import sys\n",
    "from gym.wrappers import Monitor\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Buffer(object):\n",
    "    def __init__(self, obs_spc, act_spc, model, value_model, size, gam=0.99, lam=0.97):\n",
    "        self.ptr = 0\n",
    "        self.last_idx = 0\n",
    "        self.size = size\n",
    "        self.continuous = bool(act_spc.shape)\n",
    "\n",
    "        self.model = model\n",
    "        self.value_model = value_model\n",
    "\n",
    "        self.obs_buf = tf.TensorArray(obs_spc.dtype, size)\n",
    "        self.act_buf = tf.TensorArray(act_spc.dtype, size)\n",
    "        self.rew_buf = tf.TensorArray(tf.float32, size)\n",
    "        self.prob_buf = tf.TensorArray(tf.float32, size)\n",
    "\n",
    "        self.rets = []\n",
    "        self.lens = []\n",
    "\n",
    "        self.V_hats = tf.TensorArray(tf.float32, size)\n",
    "        self.gae = tf.TensorArray(tf.float32, size)\n",
    "\n",
    "        self.gam = gam\n",
    "        self.lam = lam\n",
    "\n",
    "    # @tf.function\n",
    "    def store(self, obs, act, rew, prob):\n",
    "        self.obs_buf = self.obs_buf.write(self.ptr, obs)\n",
    "        self.act_buf = self.act_buf.write(self.ptr, act)\n",
    "        self.rew_buf = self.rew_buf.write(self.ptr, rew)\n",
    "        self.prob_buf = self.prob_buf.write(self.ptr, prob)\n",
    "        self.ptr += 1\n",
    "\n",
    "    # @tf.function\n",
    "    def finish_path(self, last_obs=None):\n",
    "        current_episode = tf.range(self.last_idx, self.ptr)\n",
    "        last_val = tf.squeeze(self.value_model(tf.expand_dims(last_obs, 0))) if last_obs is not None else 0\n",
    "\n",
    "        length = self.ptr - self.last_idx\n",
    "        ret = tf.reduce_sum(self.rew_buf.gather(current_episode)) + last_val\n",
    "\n",
    "        # v_hats = discounted cumulative sum\n",
    "        ep_rew = self.rew_buf.gather(current_episode)\n",
    "        discounts = tf.math.cumprod(tf.fill(ep_rew.shape, self.gam), exclusive=True)\n",
    "        v_hats = tf.math.cumsum(discounts * ep_rew, reverse=True)\n",
    "\n",
    "        self.lens.append(length)\n",
    "        self.rets.append(ret)\n",
    "        self.V_hats = self.V_hats.scatter(current_episode, v_hats)\n",
    "\n",
    "        Vs = tf.squeeze(value_model(self.obs_buf.gather(current_episode)), axis=1)\n",
    "        Vsp1 = tf.concat([Vs[1:], [last_val]], axis=0)\n",
    "        deltas = self.rew_buf.gather(current_episode) + self.gam * Vsp1 - Vs\n",
    "\n",
    "        # compute the advantage function (gae)\n",
    "        discounts = tf.math.cumprod(tf.fill(deltas.shape, self.gam * self.lam), exclusive=True)\n",
    "        gae = tf.math.cumsum(discounts * deltas, reverse=True)\n",
    "        self.gae = self.gae.scatter(current_episode, gae)\n",
    "\n",
    "        self.last_idx = self.ptr\n",
    "\n",
    "        if self.ptr == self.size:\n",
    "            self.obs_buf = self.obs_buf.stack()\n",
    "            self.act_buf = self.act_buf.stack()\n",
    "            self.rew_buf = self.rew_buf.stack()\n",
    "            self.prob_buf = self.prob_buf.stack()\n",
    "\n",
    "            self.V_hats = self.V_hats.stack()\n",
    "            self.gae = self.gae.stack()\n",
    "            \n",
    "    def loss(self):\n",
    "        eps = 0.1\n",
    "        obs, act, adv, logprob = self.obs_buf, self.act_buf, self.gae, self.prob_buf\n",
    "\n",
    "        if self.continuous:\n",
    "            dist = tfd.MultivariateNormalDiag(model(obs), tf.exp(self.model.log_std))\n",
    "        else:\n",
    "            dist = tfd.Categorical(logits=model(obs))\n",
    "\n",
    "        new_logprob = dist.log_prob(act)\n",
    "\n",
    "        mask = tf.cast(adv >= 0, tf.float32)\n",
    "        epsilon_clip = mask * (1 + eps) + (1 - mask) * (1 - eps)\n",
    "        ratio = tf.exp(new_logprob - logprob)\n",
    "\n",
    "        return -tf.reduce_mean(tf.minimum(ratio * adv, epsilon_clip * adv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def action(model, obs, env):\n",
    "    est = tf.squeeze(model(tf.expand_dims(obs, 0)), axis=0)\n",
    "    if env.action_space.shape:\n",
    "        dist = tfd.MultivariateNormalDiag(est, tf.exp(model.log_std))\n",
    "    else:\n",
    "        dist = tfd.Categorical(logits=est, dtype=env.action_space.dtype)\n",
    "\n",
    "    action = dist.sample()\n",
    "    logprob = tf.reduce_sum(dist.log_prob(action))\n",
    "\n",
    "    return action, logprob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_one_episode(env, buf):\n",
    "    obs_dtype = env.observation_space.dtype\n",
    "    obs = env.reset()\n",
    "    obs = tf.cast(obs, obs_dtype)\n",
    "    done = False\n",
    "\n",
    "    for i in range(buf.ptr, buf.size):\n",
    "        act, prob = action(buf.model, obs, env)\n",
    "        new_obs, rew, done, _ = env.step(act.numpy())\n",
    "\n",
    "        buf.store(obs, act, rew, prob)\n",
    "        obs = tf.cast(new_obs, obs_dtype)\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    critic_start = time.time()\n",
    "    if done:\n",
    "        buf.finish_path()\n",
    "    else:\n",
    "        while not done:\n",
    "            act, prob = action(buf.model, obs, env)\n",
    "            new_obs, rew, done, _ = env.step(act.numpy())\n",
    "        buf.finish_path(obs)\n",
    "\n",
    "    return time.time() - critic_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(env, batch_size, model, value_model, γ, λ):\n",
    "    obs_spc = env.observation_space\n",
    "    act_spc = env.action_space\n",
    "\n",
    "    batch = Buffer(obs_spc, act_spc, model, value_model, batch_size, gam=γ, lam=λ)\n",
    "    start_time = time.time()\n",
    "\n",
    "    critic_time = 0\n",
    "    while batch.ptr < batch.size:\n",
    "        critic_time += run_one_episode(env, batch)\n",
    "\n",
    "    train_start_time = time.time()\n",
    "\n",
    "    var_list = list(model.trainable_weights)\n",
    "    if act_spc.shape:\n",
    "        var_list.append(model.log_std)\n",
    "\n",
    "    opt.minimize(batch.loss, var_list=var_list)\n",
    "\n",
    "    train_time = time.time() - train_start_time\n",
    "    run_time = train_start_time - start_time\n",
    "\n",
    "    print('run time', run_time, 'critic time (included in run time):', critic_time, 'train time', train_time)\n",
    "    print('AvgEpRet:', tf.reduce_mean(batch.rets).numpy())\n",
    "\n",
    "    hist = value_model.fit(batch.obs_buf.numpy(), batch.V_hats.numpy(), batch_size=32)\n",
    "\n",
    "    return batch.rets, batch.lens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs, env, batch_size, model, value_model, γ, λ):\n",
    "    for i in range(1, epochs + 1):\n",
    "        start_time = time.time()\n",
    "        print('Epoch: ', i)\n",
    "        batch_loss = train_one_epoch(env, batch_size, model, value_model, γ, λ)\n",
    "        now = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 64)                320       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 4,610\n",
      "Trainable params: 4,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 64)                320       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 4,545\n",
      "Trainable params: 4,545\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch:  1\n",
      "run time 11.842097759246826 critic time (included in run time): 1.336843490600586 train time 0.05950284004211426\n",
      "AvgEpRet: 18.382723\n",
      "157/157 [==============================] - 1s 999us/step - loss: 110.3569\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch:  2\n",
      "run time 7.101120948791504 critic time (included in run time): 0.8874094486236572 train time 0.018674373626708984\n",
      "AvgEpRet: 34.323124\n",
      "157/157 [==============================] - 0s 942us/step - loss: 123.7058\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch:  3\n",
      "run time 6.771007299423218 critic time (included in run time): 0.5850803852081299 train time 0.01770615577697754\n",
      "AvgEpRet: 50.155617\n",
      "157/157 [==============================] - 0s 947us/step - loss: 169.6338\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch:  4\n",
      "run time 4.84989070892334 critic time (included in run time): 0.5524256229400635 train time 0.017928361892700195\n",
      "AvgEpRet: 57.72077\n",
      "157/157 [==============================] - 0s 955us/step - loss: 116.4643\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch:  5\n",
      "run time 4.780760765075684 critic time (included in run time): 0.6483745574951172 train time 0.016029834747314453\n",
      "AvgEpRet: 65.3133\n",
      "157/157 [==============================] - 0s 943us/step - loss: 93.6930\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch:  6\n",
      "run time 7.203392028808594 critic time (included in run time): 0.633697509765625 train time 0.017461538314819336\n",
      "AvgEpRet: 74.7197\n",
      "157/157 [==============================] - 0s 948us/step - loss: 71.5505\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch:  7\n",
      "run time 4.771836519241333 critic time (included in run time): 0.44322943687438965 train time 0.01736283302307129\n",
      "AvgEpRet: 94.545555\n",
      "157/157 [==============================] - 0s 958us/step - loss: 92.6100\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch:  8\n",
      "run time 4.716907739639282 critic time (included in run time): 0.4223287105560303 train time 0.017321348190307617\n",
      "AvgEpRet: 98.9082\n",
      "157/157 [==============================] - 0s 948us/step - loss: 104.2730\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch:  9\n",
      "run time 4.691822528839111 critic time (included in run time): 0.5219008922576904 train time 0.017403841018676758\n",
      "AvgEpRet: 136.17746\n",
      "157/157 [==============================] - 0s 957us/step - loss: 131.2809\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch:  10\n",
      "run time 4.640069484710693 critic time (included in run time): 0.48758816719055176 train time 0.01766347885131836\n",
      "AvgEpRet: 163.02814\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 254.1166\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch:  11\n",
      "run time 4.7676310539245605 critic time (included in run time): 0.3369448184967041 train time 0.0165557861328125\n",
      "AvgEpRet: 185.87283\n",
      "157/157 [==============================] - 0s 936us/step - loss: 207.3774\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch:  12\n",
      "run time 4.463504791259766 critic time (included in run time): 0.32929563522338867 train time 0.017866849899291992\n",
      "AvgEpRet: 185.93124\n",
      "157/157 [==============================] - 0s 944us/step - loss: 175.4231\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch:  13\n",
      "run time 9.51516079902649 critic time (included in run time): 0.5052192211151123 train time 0.019018888473510742\n",
      "AvgEpRet: 172.70108\n",
      "157/157 [==============================] - 0s 953us/step - loss: 198.4745\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch:  14\n",
      "run time 4.628741979598999 critic time (included in run time): 0.34871888160705566 train time 0.0160369873046875\n",
      "AvgEpRet: 172.71275\n",
      "157/157 [==============================] - 0s 948us/step - loss: 129.7298\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch:  15\n",
      "run time 4.61208963394165 critic time (included in run time): 0.33857107162475586 train time 0.016904592514038086\n",
      "AvgEpRet: 168.71729\n",
      "157/157 [==============================] - 0s 925us/step - loss: 97.0185\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch:  16\n",
      "run time 4.624783515930176 critic time (included in run time): 0.35617709159851074 train time 0.016408205032348633\n",
      "AvgEpRet: 156.92554\n",
      "157/157 [==============================] - 0s 936us/step - loss: 117.0664\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch:  17\n",
      "run time 4.59787654876709 critic time (included in run time): 0.3552391529083252 train time 0.017619848251342773\n",
      "AvgEpRet: 152.4478\n",
      "157/157 [==============================] - 0s 930us/step - loss: 100.9617\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch:  18\n",
      "run time 4.751266956329346 critic time (included in run time): 0.3322129249572754 train time 0.016663074493408203\n",
      "AvgEpRet: 185.51308\n",
      "157/157 [==============================] - 0s 931us/step - loss: 243.0967\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch:  19\n",
      "run time 4.411297559738159 critic time (included in run time): 0.34028077125549316 train time 0.016301393508911133\n",
      "AvgEpRet: 167.16086\n",
      "157/157 [==============================] - 0s 935us/step - loss: 187.5130\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch:  20\n",
      "run time 4.578913927078247 critic time (included in run time): 0.4797041416168213 train time 0.017632007598876953\n",
      "AvgEpRet: 185.78624\n",
      "157/157 [==============================] - 0s 940us/step - loss: 229.7821\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch:  21\n",
      "run time 4.5503294467926025 critic time (included in run time): 0.48076295852661133 train time 0.016850948333740234\n",
      "AvgEpRet: 192.87556\n",
      "157/157 [==============================] - 0s 946us/step - loss: 361.7206\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch:  22\n",
      "run time 4.693838119506836 critic time (included in run time): 0.5026164054870605 train time 0.016955852508544922\n",
      "AvgEpRet: 193.23265\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 381.4575\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch:  23\n",
      "run time 4.523762941360474 critic time (included in run time): 0.32405829429626465 train time 0.017351388931274414\n",
      "AvgEpRet: 193.31769\n",
      "157/157 [==============================] - 0s 927us/step - loss: 338.5300\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch:  24\n",
      "run time 4.317559719085693 critic time (included in run time): 0.31562113761901855 train time 0.017354726791381836\n",
      "AvgEpRet: 193.99411\n",
      "157/157 [==============================] - 0s 946us/step - loss: 436.3383\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch:  25\n",
      "run time 4.5042901039123535 critic time (included in run time): 0.46256017684936523 train time 0.015970230102539062\n",
      "AvgEpRet: 200.0\n",
      "157/157 [==============================] - 0s 897us/step - loss: 342.1515\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch:  26\n",
      "run time 4.452851295471191 critic time (included in run time): 0.4536423683166504 train time 0.01617908477783203\n",
      "AvgEpRet: 200.0\n",
      "157/157 [==============================] - 0s 910us/step - loss: 312.4448\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch:  27\n",
      "run time 4.725165367126465 critic time (included in run time): 0.4859147071838379 train time 0.016353845596313477\n",
      "AvgEpRet: 200.0\n",
      "157/157 [==============================] - 0s 962us/step - loss: 299.8809\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch:  28\n",
      "run time 4.433281183242798 critic time (included in run time): 0.4470326900482178 train time 0.016768932342529297\n",
      "AvgEpRet: 200.0\n",
      "157/157 [==============================] - 0s 928us/step - loss: 295.8056\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch:  29\n",
      "run time 4.400801658630371 critic time (included in run time): 0.3158438205718994 train time 0.015490055084228516\n",
      "AvgEpRet: 200.0\n",
      "157/157 [==============================] - 0s 911us/step - loss: 394.4746\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch:  30\n",
      "run time 4.613739490509033 critic time (included in run time): 0.30199742317199707 train time 0.015324115753173828\n",
      "AvgEpRet: 200.0\n",
      "157/157 [==============================] - 0s 924us/step - loss: 531.8375\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
     ]
    }
   ],
   "source": [
    "batch_size = 5000\n",
    "epochs = 30\n",
    "learning_rate = 1e-2\n",
    "opt = tf.optimizers.Adam(learning_rate)\n",
    "γ = .99\n",
    "λ = 0.97\n",
    "\n",
    "env_name=\"CartPole-v0\"\n",
    "env = gym.make(env_name)\n",
    "\n",
    "obs_spc = env.observation_space\n",
    "act_spc = env.action_space\n",
    "\n",
    "\n",
    "# policy/actor model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='tanh', input_shape=obs_spc.shape),\n",
    "    tf.keras.layers.Dense(64, activation='tanh'),\n",
    "    tf.keras.layers.Dense(act_spc.shape[0] if act_spc.shape else act_spc.n)\n",
    "])\n",
    "if act_spc.shape:\n",
    "    model.log_std = tf.Variable(tf.fill(env.action_space.shape, -0.5))\n",
    "model.summary()\n",
    "\n",
    "# value/critic model\n",
    "value_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='tanh', input_shape=obs_spc.shape),\n",
    "    tf.keras.layers.Dense(64, activation='tanh'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "value_model.compile('adam', loss='MSE')\n",
    "value_model.summary()\n",
    "\n",
    "with tempfile.TemporaryDirectory(prefix='recordings', dir='.')  as recordings:\n",
    "    monitor_env = Monitor(env, recordings, force=True)\n",
    "    env = monitor_env\n",
    "    train(epochs, env, batch_size, model, value_model, γ, λ)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (RLExp)",
   "language": "python",
   "name": "pycharm-2cd3141b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}